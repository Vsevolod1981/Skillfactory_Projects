    Доброго времени суток. В ходе выполнения проекта у меня было два набора данных о заемщиках банка, train и test. В наборе train помимо множества параметров была целевая
    переменная default - то есть было известно, объявил заемщик дефолт или нет. В наборе данных test были те же параметры, но целевой переменной default не было. В мою задачу
    входило предсказать вероятность дефолта для каждого заемщика из набора данных test.
    
    Для выполнения этой задачи я провел тщательный разведывательный анализ данных для набора train. На основе признака app_date (дата подачи заявки) я сгенерировал новый признак -
    сколько дней назад заявка была подана и заменил первоначальный признак новым. Преобразовал бинарные признаки в числовае и категориальные в dummy-переменные. Провел
    корреляционный анализ числовых признаков и с помощью функции mutual_info_classif провел оценку значимости категориальных признаков. Потом провел стандартизацию тех столбцов,
    где это требовалось (то есть тех стандартизация которых повышала конечную метрику ROC AUC). После чего я разбил выборку train на обучающую и тестовую и обучил модель на 
    стандартных настройках логистической регрессии. Получившаяся метрика ROC AUC - 0.73864. Затем с помощью гиперпараметров я подобрал оптимальные настройки логистической 
    регрессии и обучил модель с ними. Получившаяся метрика ROC AUC - 0.73876. Улучшение заметное и для прогноза я использовал улучщенную модель, обученную на оптимальных 
    настройках  логистческой регрессии (когда я загрузил этот же ноутбук на Kaggle то платформа не восприняла стандартные настройки - выдавала Attribute Error. Для решения этой 
    проблемы я я вместо стандартных настроек использовал LogisticRegression(solver='liblinear') и получил метрику ROC AUC - 0.73866. После применения гиперпараметров значение 
    метрики снизилось до 0.72650 поэтому на Kaggle я использовал для прогноза модель обученную на настройках LogisticRegression(solver='liblinear')).
    
    Затем я провел такой же разведывательный анализ данных для набора test и используя оптимальную модель (они разные для Kaggle и Jupyter notebook) спрогнозировал вероятность 
    дефолта для каждого заемщика из набора test. Затем удалил все лишние столбцы, оставив только client_id и default_probability. Затем отсортировал клиентов по возрастанию
    вероятности дефолта и получившийся датасет (из двух столбцов - client_id и default_probability) записал в файл sorted_submission.csv.
